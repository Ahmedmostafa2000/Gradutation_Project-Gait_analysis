{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\\\Career\\\\GradProj\\\\New deal\\\\Dataset\\\\parkinson_data.csv')\n",
    "df.drop('Unnamed: 0', axis = 1,inplace=True)\n",
    "\n",
    "df.columns = ['Time',\n",
    " 'AccV',\n",
    " 'AccML',\n",
    " 'AccAP',\n",
    " 'StartHesitation',\n",
    " 'Turn',\n",
    " 'Walking',\n",
    " 'idx',\n",
    " 'ID',\n",
    " 'len_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = np.array(df['Walking'] | df['StartHesitation'] | df['Turn'],dtype = int)\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean and standard deviation of the dataset\n",
    "data = np.asarray(df[['AccV','AccML','AccAP']] , dtype = np.float64)\n",
    "mean = np.mean(data, axis=0)\n",
    "std = np.std(data, axis=0)\n",
    "\n",
    "df[['AccV','AccML','AccAP']] = abs((data - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(np.arange(len(df)) // (4*128)).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AccV</th>\n",
       "      <th>AccML</th>\n",
       "      <th>AccAP</th>\n",
       "      <th>StartHesitation</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Walking</th>\n",
       "      <th>idx</th>\n",
       "      <th>len_df</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255.5</td>\n",
       "      <td>0.343536</td>\n",
       "      <td>0.185951</td>\n",
       "      <td>0.709099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767.5</td>\n",
       "      <td>0.343984</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>0.707673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1279.5</td>\n",
       "      <td>0.576440</td>\n",
       "      <td>0.334005</td>\n",
       "      <td>0.614446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791.5</td>\n",
       "      <td>0.934329</td>\n",
       "      <td>0.794291</td>\n",
       "      <td>0.605298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>0.582031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2303.5</td>\n",
       "      <td>1.581461</td>\n",
       "      <td>1.456504</td>\n",
       "      <td>0.926824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13790</th>\n",
       "      <td>3221.5</td>\n",
       "      <td>0.626441</td>\n",
       "      <td>0.645696</td>\n",
       "      <td>0.320737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>3733.5</td>\n",
       "      <td>0.818738</td>\n",
       "      <td>0.909519</td>\n",
       "      <td>0.382190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>4245.5</td>\n",
       "      <td>1.209386</td>\n",
       "      <td>0.781171</td>\n",
       "      <td>0.412908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>4757.5</td>\n",
       "      <td>1.172291</td>\n",
       "      <td>0.785039</td>\n",
       "      <td>1.106204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>5085.5</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.138606</td>\n",
       "      <td>1.180795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13795 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time      AccV     AccML     AccAP  StartHesitation      Turn  \\\n",
       "0       255.5  0.343536  0.185951  0.709099              0.0  0.000000   \n",
       "1       767.5  0.343984  0.185200  0.707673              0.0  0.000000   \n",
       "2      1279.5  0.576440  0.334005  0.614446              0.0  0.000000   \n",
       "3      1791.5  0.934329  0.794291  0.605298              0.0  0.582031   \n",
       "4      2303.5  1.581461  1.456504  0.926824              0.0  1.000000   \n",
       "...       ...       ...       ...       ...              ...       ...   \n",
       "13790  3221.5  0.626441  0.645696  0.320737              0.0  0.000000   \n",
       "13791  3733.5  0.818738  0.909519  0.382190              0.0  0.000000   \n",
       "13792  4245.5  1.209386  0.781171  0.412908              0.0  0.000000   \n",
       "13793  4757.5  1.172291  0.785039  1.106204              0.0  0.000000   \n",
       "13794  5085.5  0.529600  0.138606  1.180795              0.0  0.000000   \n",
       "\n",
       "       Walking    idx  len_df     class  \n",
       "0          0.0    0.0  7400.0  0.000000  \n",
       "1          0.0    0.0  7400.0  0.000000  \n",
       "2          0.0    0.0  7400.0  0.000000  \n",
       "3          0.0    0.0  7400.0  0.582031  \n",
       "4          0.0    0.0  7400.0  1.000000  \n",
       "...        ...    ...     ...       ...  \n",
       "13790      0.0  832.0  5158.0  0.000000  \n",
       "13791      0.0  832.0  5158.0  0.000000  \n",
       "13792      0.0  832.0  5158.0  0.000000  \n",
       "13793      0.0  832.0  5158.0  0.000000  \n",
       "13794      0.0  832.0  5158.0  0.000000  \n",
       "\n",
       "[13795 rows x 10 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['AccV','AccML','AccAP']][0:128].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['class']] = df[['class']]>0\n",
    "\n",
    "df[['normal','fog']] = pd.get_dummies(df['class'], prefix='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AccV</th>\n",
       "      <th>AccML</th>\n",
       "      <th>AccAP</th>\n",
       "      <th>StartHesitation</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Walking</th>\n",
       "      <th>idx</th>\n",
       "      <th>len_df</th>\n",
       "      <th>class</th>\n",
       "      <th>normal</th>\n",
       "      <th>fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255.5</td>\n",
       "      <td>0.343536</td>\n",
       "      <td>0.185951</td>\n",
       "      <td>0.709099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767.5</td>\n",
       "      <td>0.343984</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>0.707673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1279.5</td>\n",
       "      <td>0.576440</td>\n",
       "      <td>0.334005</td>\n",
       "      <td>0.614446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791.5</td>\n",
       "      <td>0.934329</td>\n",
       "      <td>0.794291</td>\n",
       "      <td>0.605298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2303.5</td>\n",
       "      <td>1.581461</td>\n",
       "      <td>1.456504</td>\n",
       "      <td>0.926824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13790</th>\n",
       "      <td>3221.5</td>\n",
       "      <td>0.626441</td>\n",
       "      <td>0.645696</td>\n",
       "      <td>0.320737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>3733.5</td>\n",
       "      <td>0.818738</td>\n",
       "      <td>0.909519</td>\n",
       "      <td>0.382190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>4245.5</td>\n",
       "      <td>1.209386</td>\n",
       "      <td>0.781171</td>\n",
       "      <td>0.412908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>4757.5</td>\n",
       "      <td>1.172291</td>\n",
       "      <td>0.785039</td>\n",
       "      <td>1.106204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>5085.5</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.138606</td>\n",
       "      <td>1.180795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13795 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time      AccV     AccML     AccAP  StartHesitation      Turn  \\\n",
       "0       255.5  0.343536  0.185951  0.709099              0.0  0.000000   \n",
       "1       767.5  0.343984  0.185200  0.707673              0.0  0.000000   \n",
       "2      1279.5  0.576440  0.334005  0.614446              0.0  0.000000   \n",
       "3      1791.5  0.934329  0.794291  0.605298              0.0  0.582031   \n",
       "4      2303.5  1.581461  1.456504  0.926824              0.0  1.000000   \n",
       "...       ...       ...       ...       ...              ...       ...   \n",
       "13790  3221.5  0.626441  0.645696  0.320737              0.0  0.000000   \n",
       "13791  3733.5  0.818738  0.909519  0.382190              0.0  0.000000   \n",
       "13792  4245.5  1.209386  0.781171  0.412908              0.0  0.000000   \n",
       "13793  4757.5  1.172291  0.785039  1.106204              0.0  0.000000   \n",
       "13794  5085.5  0.529600  0.138606  1.180795              0.0  0.000000   \n",
       "\n",
       "       Walking    idx  len_df  class  normal  fog  \n",
       "0          0.0    0.0  7400.0  False       1    0  \n",
       "1          0.0    0.0  7400.0  False       1    0  \n",
       "2          0.0    0.0  7400.0  False       1    0  \n",
       "3          0.0    0.0  7400.0   True       0    1  \n",
       "4          0.0    0.0  7400.0   True       0    1  \n",
       "...        ...    ...     ...    ...     ...  ...  \n",
       "13790      0.0  832.0  5158.0  False       1    0  \n",
       "13791      0.0  832.0  5158.0  False       1    0  \n",
       "13792      0.0  832.0  5158.0  False       1    0  \n",
       "13793      0.0  832.0  5158.0  False       1    0  \n",
       "13794      0.0  832.0  5158.0  False       1    0  \n",
       "\n",
       "[13795 rows x 12 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['AccV','AccML','AccAP']]\n",
    "y = df[['fog','normal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Dense,BatchNormalization,Input,Bidirectional,Conv1D,MaxPooling1D,Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint_tweaked(tf.keras.callbacks.ModelCheckpoint):\n",
    "    def __init__(self,\n",
    "                   filepath,\n",
    "                   monitor='val_loss',\n",
    "                   verbose=0,\n",
    "                   save_best_only=False,\n",
    "                   save_weights_only=False,\n",
    "                   mode='auto',\n",
    "                   save_freq='epoch',\n",
    "                   options=None,\n",
    "                   **kwargs):\n",
    "        \n",
    "        #Change tf_utils source package.\n",
    "        from tensorflow.python.keras.utils import tf_utils\n",
    "        \n",
    "        super(ModelCheckpoint_tweaked, self).__init__(filepath,\n",
    "                   monitor,\n",
    "                   verbose,\n",
    "                   save_best_only,\n",
    "                   save_weights_only,\n",
    "                   mode,\n",
    "                   save_freq,\n",
    "                   options,\n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"accuracy\",factor=0.5,patience=5,)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=30)\n",
    "checkpointer = ModelCheckpoint_tweaked(filepath='best.hdf5', verbose=0, save_best_only=True)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\"model_history_log.csv\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, None, 100)         400       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, None, 100)         10100     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, None, 100)         10100     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, None, 2)           202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,802\n",
      "Trainable params: 20,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.50)\n",
    "\n",
    "model_aug = Sequential([\n",
    "    Input((None,3)),\n",
    "    Dense(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation = 'softmax') \n",
    "])\n",
    "\n",
    "model_aug.compile(  optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),#, clipvalue=0.5),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'],\n",
    "                \n",
    "                )\n",
    "\n",
    "model_aug.summary()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.6480 - accuracy: 0.6277WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.6483 - accuracy: 0.6272 - val_loss: 0.6314 - val_accuracy: 0.6406 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6393 - accuracy: 0.6463 - val_loss: 0.6304 - val_accuracy: 0.6536 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6377 - accuracy: 0.6507 - val_loss: 0.6342 - val_accuracy: 0.6420 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6364 - accuracy: 0.6511 - val_loss: 0.6292 - val_accuracy: 0.6652 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6367 - accuracy: 0.6544 - val_loss: 0.6308 - val_accuracy: 0.6551 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6353 - accuracy: 0.6510 - val_loss: 0.6309 - val_accuracy: 0.6522 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6359 - accuracy: 0.6559 - val_loss: 0.6362 - val_accuracy: 0.6362 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6365 - accuracy: 0.6549 - val_loss: 0.6318 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6364 - accuracy: 0.6516 - val_loss: 0.6375 - val_accuracy: 0.6290 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6351 - accuracy: 0.6549 - val_loss: 0.6375 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6351 - accuracy: 0.6564 - val_loss: 0.6358 - val_accuracy: 0.6333 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6361 - accuracy: 0.6532 - val_loss: 0.6331 - val_accuracy: 0.6493 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6343 - accuracy: 0.6601 - val_loss: 0.6366 - val_accuracy: 0.6319 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6362 - accuracy: 0.6523 - val_loss: 0.6284 - val_accuracy: 0.6696 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6350 - accuracy: 0.6574 - val_loss: 0.6328 - val_accuracy: 0.6493 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.6549 - val_loss: 0.6394 - val_accuracy: 0.6232 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6354 - accuracy: 0.6553 - val_loss: 0.6325 - val_accuracy: 0.6464 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6349 - accuracy: 0.6609 - val_loss: 0.6320 - val_accuracy: 0.6478 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6347 - accuracy: 0.6565 - val_loss: 0.6281 - val_accuracy: 0.6623 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6347 - accuracy: 0.6582 - val_loss: 0.6366 - val_accuracy: 0.6319 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.6541 - val_loss: 0.6306 - val_accuracy: 0.6725 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.6572 - val_loss: 0.6335 - val_accuracy: 0.6478 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.6600 - val_loss: 0.6368 - val_accuracy: 0.6377 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6345 - accuracy: 0.6574 - val_loss: 0.6331 - val_accuracy: 0.6449 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6341 - accuracy: 0.6598 - val_loss: 0.6346 - val_accuracy: 0.6391 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6580 - val_loss: 0.6325 - val_accuracy: 0.6522 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.6586 - val_loss: 0.6318 - val_accuracy: 0.6522 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6344 - accuracy: 0.6589 - val_loss: 0.6318 - val_accuracy: 0.6551 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6343 - accuracy: 0.6604 - val_loss: 0.6314 - val_accuracy: 0.6507 - lr: 2.5000e-04\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6583 - val_loss: 0.6330 - val_accuracy: 0.6493 - lr: 2.5000e-04\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6342 - accuracy: 0.6602 - val_loss: 0.6323 - val_accuracy: 0.6507 - lr: 2.5000e-04\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6348 - accuracy: 0.6586 - val_loss: 0.6336 - val_accuracy: 0.6449 - lr: 2.5000e-04\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6584 - val_loss: 0.6322 - val_accuracy: 0.6464 - lr: 2.5000e-04\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6340 - accuracy: 0.6590 - val_loss: 0.6319 - val_accuracy: 0.6507 - lr: 1.2500e-04\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.6597 - val_loss: 0.6325 - val_accuracy: 0.6507 - lr: 1.2500e-04\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.6602 - val_loss: 0.6326 - val_accuracy: 0.6493 - lr: 1.2500e-04\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.6596 - val_loss: 0.6325 - val_accuracy: 0.6536 - lr: 1.2500e-04\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6602 - val_loss: 0.6314 - val_accuracy: 0.6507 - lr: 1.2500e-04\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6337 - accuracy: 0.6611 - val_loss: 0.6323 - val_accuracy: 0.6507 - lr: 6.2500e-05\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.6584 - val_loss: 0.6324 - val_accuracy: 0.6536 - lr: 6.2500e-05\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.6597 - val_loss: 0.6324 - val_accuracy: 0.6522 - lr: 6.2500e-05\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6595 - val_loss: 0.6324 - val_accuracy: 0.6522 - lr: 6.2500e-05\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.6593 - val_loss: 0.6323 - val_accuracy: 0.6507 - lr: 6.2500e-05\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6338 - accuracy: 0.6600 - val_loss: 0.6323 - val_accuracy: 0.6522 - lr: 6.2500e-05\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.6590 - val_loss: 0.6325 - val_accuracy: 0.6522 - lr: 3.1250e-05\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6331 - accuracy: 0.6623 - val_loss: 0.6321 - val_accuracy: 0.6493 - lr: 3.1250e-05\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6611 - val_loss: 0.6320 - val_accuracy: 0.6507 - lr: 3.1250e-05\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6341 - accuracy: 0.6602 - val_loss: 0.6323 - val_accuracy: 0.6522 - lr: 3.1250e-05\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6339 - accuracy: 0.6616 - val_loss: 0.6325 - val_accuracy: 0.6507 - lr: 3.1250e-05\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.6604 - val_loss: 0.6324 - val_accuracy: 0.6522 - lr: 3.1250e-05\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6329 - accuracy: 0.6599 - val_loss: 0.6319 - val_accuracy: 0.6507 - lr: 3.1250e-05\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6599 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 1.5625e-05\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6335 - accuracy: 0.6610 - val_loss: 0.6322 - val_accuracy: 0.6493 - lr: 1.5625e-05\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.6627 - val_loss: 0.6321 - val_accuracy: 0.6493 - lr: 1.5625e-05\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.6603 - val_loss: 0.6325 - val_accuracy: 0.6522 - lr: 1.5625e-05\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6340 - accuracy: 0.6598 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 1.5625e-05\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6340 - accuracy: 0.6616 - val_loss: 0.6324 - val_accuracy: 0.6522 - lr: 1.5625e-05\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6597 - val_loss: 0.6325 - val_accuracy: 0.6522 - lr: 1.5625e-05\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6604 - val_loss: 0.6323 - val_accuracy: 0.6522 - lr: 1.5625e-05\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6577 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 7.8125e-06\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6337 - accuracy: 0.6603 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 7.8125e-06\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.6605 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 7.8125e-06\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6334 - accuracy: 0.6599 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 7.8125e-06\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.6601 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 7.8125e-06\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6332 - accuracy: 0.6613 - val_loss: 0.6322 - val_accuracy: 0.6493 - lr: 3.9063e-06\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6609 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 3.9063e-06\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6338 - accuracy: 0.6615 - val_loss: 0.6322 - val_accuracy: 0.6493 - lr: 3.9063e-06\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6334 - accuracy: 0.6600 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 3.9063e-06\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.6615 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 3.9063e-06\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6622 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 1.9531e-06\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.6601 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 1.9531e-06\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6337 - accuracy: 0.6592 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 1.9531e-06\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.6605 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 1.9531e-06\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6335 - accuracy: 0.6605 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 1.9531e-06\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6334 - accuracy: 0.6606 - val_loss: 0.6322 - val_accuracy: 0.6507 - lr: 9.7656e-07\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6604 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 9.7656e-07\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6332 - accuracy: 0.6617 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 9.7656e-07\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6342 - accuracy: 0.6596 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 9.7656e-07\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6605 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 9.7656e-07\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6606 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 4.8828e-07\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6591 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 4.8828e-07\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6334 - accuracy: 0.6619 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 4.8828e-07\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6338 - accuracy: 0.6602 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 4.8828e-07\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6331 - accuracy: 0.6593 - val_loss: 0.6322 - val_accuracy: 0.6522 - lr: 4.8828e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2a59df8e0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aug.fit(x_train, y_train, batch_size = 256, epochs = 200, callbacks = [rlr,earlystop,checkpointer,csv_logger],validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.6377\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "22/22 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model_aug.evaluate(x_test,y_test)\n",
    "\n",
    "y_pred = model_aug.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model_aug, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualkeras import layered_view\n",
    "layered_view(model_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, None, 100)         400       \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, None, 100)         10100     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, None, 100)         10100     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, None, 100)         10100     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, None, 2)           202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,902\n",
      "Trainable params: 30,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.50)\n",
    "\n",
    "model_aug = Sequential([\n",
    "    Input((None,3)),\n",
    "    Dense(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(100),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation = 'softmax') \n",
    "])\n",
    "\n",
    "model_aug.compile(  optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),#, clipvalue=0.5),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'],\n",
    "                \n",
    "                )\n",
    "\n",
    "model_aug.summary()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.6609 - accuracy: 0.6098WARNING:tensorflow:Model was constructed with shape (None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 3).\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.6609 - accuracy: 0.6097 - val_loss: 0.6421 - val_accuracy: 0.6493 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6393 - accuracy: 0.6444 - val_loss: 0.6357 - val_accuracy: 0.6623 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.6491 - val_loss: 0.6342 - val_accuracy: 0.6638 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6389 - accuracy: 0.6508 - val_loss: 0.6378 - val_accuracy: 0.6594 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6382 - accuracy: 0.6492 - val_loss: 0.6338 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6377 - accuracy: 0.6491 - val_loss: 0.6389 - val_accuracy: 0.6565 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6376 - accuracy: 0.6517 - val_loss: 0.6360 - val_accuracy: 0.6623 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.6359 - accuracy: 0.6536 - val_loss: 0.6337 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6368 - accuracy: 0.6511 - val_loss: 0.6322 - val_accuracy: 0.6696 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.6516 - val_loss: 0.6330 - val_accuracy: 0.6638 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6367 - accuracy: 0.6493 - val_loss: 0.6367 - val_accuracy: 0.6594 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.6541 - val_loss: 0.6388 - val_accuracy: 0.6493 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6358 - accuracy: 0.6533 - val_loss: 0.6390 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6361 - accuracy: 0.6553 - val_loss: 0.6362 - val_accuracy: 0.6638 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6360 - accuracy: 0.6511 - val_loss: 0.6326 - val_accuracy: 0.6652 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6363 - accuracy: 0.6561 - val_loss: 0.6379 - val_accuracy: 0.6522 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6362 - accuracy: 0.6565 - val_loss: 0.6388 - val_accuracy: 0.6522 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6360 - accuracy: 0.6491 - val_loss: 0.6328 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6371 - accuracy: 0.6489 - val_loss: 0.6354 - val_accuracy: 0.6609 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6360 - accuracy: 0.6520 - val_loss: 0.6397 - val_accuracy: 0.6435 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.6514 - val_loss: 0.6370 - val_accuracy: 0.6594 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6355 - accuracy: 0.6540 - val_loss: 0.6376 - val_accuracy: 0.6551 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6353 - accuracy: 0.6528 - val_loss: 0.6321 - val_accuracy: 0.6638 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.6512 - val_loss: 0.6320 - val_accuracy: 0.6623 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.6528 - val_loss: 0.6384 - val_accuracy: 0.6536 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6353 - accuracy: 0.6538 - val_loss: 0.6351 - val_accuracy: 0.6638 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.6571 - val_loss: 0.6360 - val_accuracy: 0.6594 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6353 - accuracy: 0.6543 - val_loss: 0.6360 - val_accuracy: 0.6580 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.6563 - val_loss: 0.6331 - val_accuracy: 0.6667 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6348 - accuracy: 0.6557 - val_loss: 0.6365 - val_accuracy: 0.6594 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6355 - accuracy: 0.6554 - val_loss: 0.6337 - val_accuracy: 0.6652 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6353 - accuracy: 0.6552 - val_loss: 0.6332 - val_accuracy: 0.6638 - lr: 5.0000e-04\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.6579 - val_loss: 0.6340 - val_accuracy: 0.6667 - lr: 2.5000e-04\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6351 - accuracy: 0.6582 - val_loss: 0.6355 - val_accuracy: 0.6638 - lr: 2.5000e-04\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6356 - accuracy: 0.6543 - val_loss: 0.6334 - val_accuracy: 0.6652 - lr: 2.5000e-04\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.6348 - accuracy: 0.6574 - val_loss: 0.6345 - val_accuracy: 0.6638 - lr: 2.5000e-04\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6349 - accuracy: 0.6572 - val_loss: 0.6344 - val_accuracy: 0.6652 - lr: 2.5000e-04\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6563 - val_loss: 0.6352 - val_accuracy: 0.6638 - lr: 2.5000e-04\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6347 - accuracy: 0.6565 - val_loss: 0.6342 - val_accuracy: 0.6667 - lr: 2.5000e-04\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.6347 - accuracy: 0.6563 - val_loss: 0.6337 - val_accuracy: 0.6623 - lr: 1.2500e-04\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.6580 - val_loss: 0.6352 - val_accuracy: 0.6638 - lr: 1.2500e-04\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6349 - accuracy: 0.6586 - val_loss: 0.6346 - val_accuracy: 0.6638 - lr: 1.2500e-04\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6347 - accuracy: 0.6557 - val_loss: 0.6344 - val_accuracy: 0.6638 - lr: 1.2500e-04\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6350 - accuracy: 0.6556 - val_loss: 0.6345 - val_accuracy: 0.6652 - lr: 1.2500e-04\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.6592 - val_loss: 0.6342 - val_accuracy: 0.6638 - lr: 1.2500e-04\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.6546 - val_loss: 0.6340 - val_accuracy: 0.6638 - lr: 1.2500e-04\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6349 - accuracy: 0.6574 - val_loss: 0.6342 - val_accuracy: 0.6638 - lr: 1.2500e-04\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6346 - accuracy: 0.6572 - val_loss: 0.6347 - val_accuracy: 0.6638 - lr: 1.2500e-04\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6569 - val_loss: 0.6334 - val_accuracy: 0.6667 - lr: 1.2500e-04\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6347 - accuracy: 0.6589 - val_loss: 0.6347 - val_accuracy: 0.6652 - lr: 1.2500e-04\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6344 - accuracy: 0.6574 - val_loss: 0.6341 - val_accuracy: 0.6652 - lr: 6.2500e-05\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6570 - val_loss: 0.6345 - val_accuracy: 0.6652 - lr: 6.2500e-05\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6343 - accuracy: 0.6573 - val_loss: 0.6345 - val_accuracy: 0.6652 - lr: 6.2500e-05\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.6579 - val_loss: 0.6346 - val_accuracy: 0.6638 - lr: 6.2500e-05\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6349 - accuracy: 0.6588 - val_loss: 0.6346 - val_accuracy: 0.6623 - lr: 6.2500e-05\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6347 - accuracy: 0.6566 - val_loss: 0.6345 - val_accuracy: 0.6638 - lr: 3.1250e-05\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6344 - accuracy: 0.6596 - val_loss: 0.6344 - val_accuracy: 0.6652 - lr: 3.1250e-05\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6348 - accuracy: 0.6578 - val_loss: 0.6342 - val_accuracy: 0.6638 - lr: 3.1250e-05\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6343 - accuracy: 0.6587 - val_loss: 0.6343 - val_accuracy: 0.6652 - lr: 3.1250e-05\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6344 - accuracy: 0.6565 - val_loss: 0.6345 - val_accuracy: 0.6652 - lr: 3.1250e-05\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6338 - accuracy: 0.6574 - val_loss: 0.6342 - val_accuracy: 0.6638 - lr: 3.1250e-05\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6347 - accuracy: 0.6573 - val_loss: 0.6345 - val_accuracy: 0.6652 - lr: 3.1250e-05\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6342 - accuracy: 0.6576 - val_loss: 0.6345 - val_accuracy: 0.6652 - lr: 1.5625e-05\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.6569 - val_loss: 0.6344 - val_accuracy: 0.6652 - lr: 1.5625e-05\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.6591 - val_loss: 0.6344 - val_accuracy: 0.6652 - lr: 1.5625e-05\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6342 - accuracy: 0.6557 - val_loss: 0.6344 - val_accuracy: 0.6652 - lr: 1.5625e-05\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6559 - val_loss: 0.6344 - val_accuracy: 0.6652 - lr: 1.5625e-05\n",
      "Epoch 68/200\n",
      "21/49 [===========>..................] - ETA: 0s - loss: 0.6389 - accuracy: 0.6535"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Career\\GradProj\\New deal\\models\\s2l\\4 seconds\\100 LSTM\\s2l_4.Ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Career/GradProj/New%20deal/models/s2l/4%20seconds/100%20LSTM/s2l_4.Ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_aug\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size \u001b[39m=\u001b[39;49m \u001b[39m256\u001b[39;49m, epochs \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m, callbacks \u001b[39m=\u001b[39;49m [rlr,earlystop,checkpointer,csv_logger],validation_data\u001b[39m=\u001b[39;49m(x_val,y_val))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_aug.fit(x_train, y_train, batch_size = 256, epochs = 200, callbacks = [rlr,earlystop,checkpointer,csv_logger],validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070596458527493"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['fog'].sum()/y['normal'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
